\chapter{Model Evaluation}
\label{chapter:model_evaluation}
  This chapter details the testing done on the final system, as well as some proposals for the underlying model could be tested in the long term.

  \section{Validity}
    \subsection{Supporting Evidence}
      \todo{
        \item Consistent with Constructivist Theory
        \item Consistent with Bloom's taxonomy (layers depend on lower layers), though it can work even if the layers aren't consistently the same (some of the layers in the taxonomy are debated)
        \item Humans appear to be \emph{at least} computers
        \item The consequences of the model are consistent with many things we know about learning, including simpler writing styles, ordered approach to learning, multiple ways to teach things etc
      }

    \subsection{Further Testing}
      \todo{
        \item Further testing necessary
        \item Applying the model to a variety of different subjects would check that it doesn't break down with certain types of knowledge
        \item See extensions for a discussion about skills that aren't completely brain based
        \item Simplest way to falsify the model is to show that humans aren't as capable as computers
        \item Showing humans are capable of things that computers aren't would show a limitation of the model, though it could still be useful for a large amount of material
      }

  \section{Value}
    \subsection{Applying the Model}
      \todo{
        \item Attempted applying the model to AAI
        \item No written content, just the graph
        \item Ran into a lot of problems, including the following
        \item Inconsistent usage of terminology: Handling different languages (different terminology can be considered a different language, even though it's all English) is important. Simple solution is to resolve conflicting terminology. Complex solution unknown.
        \item Tried to apply model from bottom up, looking for small bits of knowledge and then identifying dependencies: Mistake: Should have refined from the top down!
        \item Include graph?
      }

    \subsection{Performance Over Existing Methods}
      \todo{
        \item Testing the performance over existing methods is hard:
        \item To do a fair test, the starting knowledge of participants in a test must be carefully controlled
        \item Basic plan: Test people on a topic before learning: They must get zero on the tests, or at least no better than chance, indicating no knowledge
        \item Different groups of people would be taught using both traditional methods and using the applications of the model
        \item Same time given to all groups
        \item Final test results will show which methods managed to teach more: There must be more material to learn than there is time to learn: 100\% scores all around would tell us nothing.
        \item Maybe stop when one group reaches a set \% then test everyone else?
        \item Important to also track things like cost: How much effort is required to construct the resources for each method
      }

  \section{Scalability}
    \todo{
      \item Methods for refining the graph mean a publicly curated graph should be able to survive being worked on by loads of people
      \item really needs more thought
    }
